{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext_comparison_function import eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import neattext.functions as nfx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>repo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"script path builtin variable (a la `__file__`...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"give lobby creator extra powers hey</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>dmtmm congratulations! guys great works past h...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"router - avoid regex matching possible given ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"improve command history currently</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 labels                                       descriptions  \\\n",
       "0  __label__enhancement  \"script path builtin variable (a la `__file__`...   \n",
       "1  __label__enhancement               \"give lobby creator extra powers hey   \n",
       "2  __label__enhancement  dmtmm congratulations! guys great works past h...   \n",
       "3  __label__enhancement  \"router - avoid regex matching possible given ...   \n",
       "4  __label__enhancement                 \"improve command history currently   \n",
       "\n",
       "  repo_name  \n",
       "0     other  \n",
       "1     other  \n",
       "2     other  \n",
       "3     other  \n",
       "4     other  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# custom data set\n",
    "data_in_path = r\"..\\dataset\\CLEAN_balanced_data.csv\"\n",
    "data_out_path = r\"..\\results\\output.txt\"\n",
    "df = pd.read_csv(data_in_path)\n",
    "df = df.dropna()\n",
    "# df['data'] = \"__label__\" + df['labels'] + \" \" + df['descriptions']\n",
    "# df['data'] = df['labels'] + \" \" + df['descriptions']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29625, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"..\\dataset\\ft_bal.txt\"\n",
    "# df['data'] = \"__label__\" + df['labels'] + \" \" + df['descriptions']\n",
    "df['data'] = df['labels'] + \" \" + df['descriptions']\n",
    "df_file = df[['data']]\n",
    "df_file.to_csv(data_path,index=False,header=False,sep=\"\\t\",encoding='utf-8-sig')\n",
    "df_file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dataset to array\n",
      "New tenfold iteration: 1 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "(3208, 0.635286783042394, 0.635286783042394)\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 1,\n",
      "    \"F1\": 0.635286783042394,\n",
      "    \"Recall\": 0.635286783042394,\n",
      "    \"Precision\": 0.635286783042394\n",
      "}\n",
      "New tenfold iteration: 2 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "(3198, 0.6125703564727955, 0.6125703564727955)\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 2,\n",
      "    \"F1\": 0.6125703564727955,\n",
      "    \"Recall\": 0.6125703564727955,\n",
      "    \"Precision\": 0.6125703564727955\n",
      "}\n",
      "Done with 10 fold validation\n",
      "{\n",
      "    \"Results\": {\n",
      "        \"F1\": 0.12478571395151894,\n",
      "        \"Recall\": 0.12478571395151894,\n",
      "        \"Precision\": 0.12478571395151894\n",
      "    },\n",
      "    \"Details\": [\n",
      "        {\n",
      "            \"10-Fold iteration:\": 1,\n",
      "            \"F1\": 0.635286783042394,\n",
      "            \"Recall\": 0.635286783042394,\n",
      "            \"Precision\": 0.635286783042394\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 2,\n",
      "            \"F1\": 0.6125703564727955,\n",
      "            \"Recall\": 0.6125703564727955,\n",
      "            \"Precision\": 0.6125703564727955\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Writing output to file\n",
      "Deleting tmp files\n",
      "Exit.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# path_train = os.path.dirname(__file__) + './tmp/tmp_train.txt'\n",
    "# path_test = os.path.dirname(__file__) + './tmp/tmp_test.txt'\n",
    "\n",
    "path_test = r\"..\\temp\\temp_eval.txt\"\n",
    "path_train = r\"..\\temp\\temp_train.txt\"\n",
    "data_out_path = r\"..\\results\\output_ft_regular_TEST.txt\"\n",
    "data_set = data_path\n",
    "f_out = data_out_path\n",
    "# try:\n",
    "print(\"Converting dataset to array\")\n",
    "# f = open(data_set, 'r+', encoding=\"UTF-8\")\n",
    "\n",
    "data = array(df_file['data'])\n",
    "# f.close()\n",
    "\n",
    "# array for details\n",
    "fold_outputs = []\n",
    "\n",
    "# 10 fold loop\n",
    "kfold = KFold(2, shuffle=True, random_state=1)\n",
    "fold = 1\n",
    "for train, test in kfold.split(data):\n",
    "    print(\"New tenfold iteration:\", str(fold), \"-----------------------------------------\")\n",
    "    print(\"Creating train file\")\n",
    "    tmp_train = data[train]\n",
    "    pd.DataFrame(tmp_train).to_csv(path_train,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "    print(\"Creating test file\")\n",
    "    tmp_test = data[test]\n",
    "    pd.DataFrame(tmp_test).to_csv(path_test,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"start training...\")\n",
    "    # use this model if you want to enable auto-tuning. Sadly we did not get it to work during our project\n",
    "    # model = fasttext.train_supervised(input=path_train, autotuneValidationFile=path_test, autotuneDuration=600)\n",
    "    # model = fasttext.train_supervised(input=path_train)  # normal fasttext classification without autotuning\n",
    "    model = fasttext.train_supervised(input=path_train, lr=1.0, epoch=25, wordNgrams=2)\n",
    "    print(\"start testing...\")\n",
    "    res = model.test(path_test)\n",
    "    print(res)\n",
    "    # get benchmarks\n",
    "    precision = res[1]\n",
    "    recall = res[2]\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    result = {\n",
    "        '10-Fold iteration:': fold,\n",
    "        'F1': f1,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision\n",
    "        # 'acuracy'\n",
    "    }\n",
    "    # log\n",
    "    print(\"Fold over, here are results: \")\n",
    "    print(json.dumps(result, indent=4))\n",
    "    fold_outputs.append(result)\n",
    "    fold += 1\n",
    "print(\"Done with 10 fold validation\")\n",
    "# calculate over-all results\n",
    "mean_recall = 0\n",
    "mean_precision = 0\n",
    "mean_f1 = 0\n",
    "for f in fold_outputs:\n",
    "    mean_f1 += (f['F1'] / 10)\n",
    "    mean_recall += (f['Recall'] / 10)\n",
    "    mean_precision += (f['Precision'] / 10)\n",
    "    # compile results as json\n",
    "output = {\n",
    "    'Results': {\n",
    "        'F1': mean_f1,\n",
    "        'Recall': mean_recall,\n",
    "        'Precision': mean_precision\n",
    "    },\n",
    "    'Details': fold_outputs\n",
    "}\n",
    "dump = json.dumps(output, indent=4)\n",
    "print(dump)\n",
    "# write to output\n",
    "print(\"Writing output to file\")\n",
    "o = open(f_out, 'w', encoding=\"UTF-8\")\n",
    "o.write(dump)\n",
    "o.close()\n",
    "# except:\n",
    "# print(\"An Error occurred\")\n",
    "# # in any case delete existing temporary files\n",
    "# finally:\n",
    "print(\"Deleting tmp files\")\n",
    "if os.path.exists(path_train):\n",
    "    os.remove(path_train)\n",
    "if os.path.exists(path_test):\n",
    "    os.remove(path_test)\n",
    "print(\"Exit.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan / work steps\n",
    "need to split the repo level data into test/train datasets\n",
    "\n",
    "need to train a model with a simple test/ train split from the balanced data\n",
    "then use that model to predict on each of the repo datasets\n",
    "\n",
    "then split each repo dataset into test train\n",
    "\n",
    "include the repo data inside the training data\n",
    "then repredict with it\n",
    "see if it improves it at all. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to organize the data into separate groups for each of the different repo\n",
    "then run the eval function over each of them. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating creating model and using it to predict repo issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>repo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"script path builtin variable (a la `__file__`...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"give lobby creator extra powers hey</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>dmtmm congratulations! guys great works past h...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"router - avoid regex matching possible given ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"improve command history currently</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 labels                                       descriptions  \\\n",
       "0  __label__enhancement  \"script path builtin variable (a la `__file__`...   \n",
       "1  __label__enhancement               \"give lobby creator extra powers hey   \n",
       "2  __label__enhancement  dmtmm congratulations! guys great works past h...   \n",
       "3  __label__enhancement  \"router - avoid regex matching possible given ...   \n",
       "4  __label__enhancement                 \"improve command history currently   \n",
       "\n",
       "  repo_name  \n",
       "0     other  \n",
       "1     other  \n",
       "2     other  \n",
       "3     other  \n",
       "4     other  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# custom data set\n",
    "data_in_path = r\"..\\dataset\\CLEAN_balanced_data.csv\"\n",
    "data_out_path = r\"..\\results\\output.txt\"\n",
    "data_df = pd.read_csv(data_in_path)\n",
    "data_df = data_df.dropna()\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to train and dev samples\n",
    "RANDOM_SEED = 12\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_df['descriptions'], data_df['labels'],\n",
    "                                                 test_size=0.3,\n",
    "                                                 random_state=RANDOM_SEED)\n",
    "df_train = pd.concat([x_train, y_train], axis=1).reset_index(drop=True)\n",
    "df_eval = pd.concat([x_test, y_test], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20737, 2)\n",
      "(8888, 2)\n",
      "(29625, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_eval.shape)\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['data'] = df_train['labels'] + \" \" + df_train['descriptions']\n",
    "df_train = df_train[['data']]\n",
    "\n",
    "df_eval['data'] = df_eval['labels'] + \" \" + df_eval['descriptions']\n",
    "df_eval = df_eval[['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train file\n",
      "Creating test file\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating train file\")\n",
    "df_train.to_csv(path_train,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "print(\"Creating test file\")\n",
    "df_eval.to_csv(path_test,index=False,header=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=path_train, lr=1.0, epoch=25, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>labels</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>repo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4625</td>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>clarify sdl_locktexture() description # bug re...</td>\n",
       "      <td>https://api.github.com/repos/libsdl-org/SDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4655</td>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>[patch] add stadia controller gamecontrollerdb...</td>\n",
       "      <td>https://api.github.com/repos/libsdl-org/SDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4657</td>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>feature: sdl_openurl() # bug report migrated o...</td>\n",
       "      <td>https://api.github.com/repos/libsdl-org/SDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4730</td>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>sdl mutex implementation subpar # bug report m...</td>\n",
       "      <td>https://api.github.com/repos/libsdl-org/SDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4750</td>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>allow desktop opengl contexts egl # bug report...</td>\n",
       "      <td>https://api.github.com/repos/libsdl-org/SDL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                labels  \\\n",
       "0        4625  __label__enhancement   \n",
       "1        4655  __label__enhancement   \n",
       "2        4657  __label__enhancement   \n",
       "3        4730  __label__enhancement   \n",
       "4        4750  __label__enhancement   \n",
       "\n",
       "                                        descriptions  \\\n",
       "0  clarify sdl_locktexture() description # bug re...   \n",
       "1  [patch] add stadia controller gamecontrollerdb...   \n",
       "2  feature: sdl_openurl() # bug report migrated o...   \n",
       "3  sdl mutex implementation subpar # bug report m...   \n",
       "4  allow desktop opengl contexts egl # bug report...   \n",
       "\n",
       "                                     repo_name  \n",
       "0  https://api.github.com/repos/libsdl-org/SDL  \n",
       "1  https://api.github.com/repos/libsdl-org/SDL  \n",
       "2  https://api.github.com/repos/libsdl-org/SDL  \n",
       "3  https://api.github.com/repos/libsdl-org/SDL  \n",
       "4  https://api.github.com/repos/libsdl-org/SDL  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # save train and eval dataframes to csv\n",
    "# # get repo data \n",
    "df_all = pd.read_csv(r\"..\\dataset\\CLEAN_multiple_projects_benchmark_data.csv\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/Kaiserreich/Kaise...</td>\n",
       "      <td>7476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/Microsoft/vscode</td>\n",
       "      <td>8165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/Regalis11/Barotrauma</td>\n",
       "      <td>3769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/dbeaver/dbeaver</td>\n",
       "      <td>6099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/godotengine/godot</td>\n",
       "      <td>13535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://api.github.com/repos/hashicorp/terraform</td>\n",
       "      <td>6816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://api.github.com/repos/libsdl-org/SDL</td>\n",
       "      <td>3379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://api.github.com/repos/microsoft/vscode</td>\n",
       "      <td>8288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://api.github.com/repos/qgis/QGIS</td>\n",
       "      <td>4609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://api.github.com/repos/rstudio/rstudio</td>\n",
       "      <td>2753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://api.github.com/repos/symfony/symfony</td>\n",
       "      <td>4165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://api.github.com/repos/tgstation/tgstation</td>\n",
       "      <td>5574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_name  descriptions\n",
       "0   https://api.github.com/repos/Kaiserreich/Kaise...          7476\n",
       "1       https://api.github.com/repos/Microsoft/vscode          8165\n",
       "2   https://api.github.com/repos/Regalis11/Barotrauma          3769\n",
       "3        https://api.github.com/repos/dbeaver/dbeaver          6099\n",
       "4      https://api.github.com/repos/godotengine/godot         13535\n",
       "5    https://api.github.com/repos/hashicorp/terraform          6816\n",
       "6         https://api.github.com/repos/libsdl-org/SDL          3379\n",
       "7       https://api.github.com/repos/microsoft/vscode          8288\n",
       "8              https://api.github.com/repos/qgis/QGIS          4609\n",
       "9        https://api.github.com/repos/rstudio/rstudio          2753\n",
       "10       https://api.github.com/repos/symfony/symfony          4165\n",
       "11   https://api.github.com/repos/tgstation/tgstation          5574"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grp = df_all.groupby(['repo_name']).agg({'descriptions':'count'}).reset_index()\n",
    "# df_grp.columns = ['Labels','Row Count']\n",
    "# print(df.head())\n",
    "df_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SDL',\n",
       " 'dbeaver',\n",
       " 'rstudio',\n",
       " 'symfony',\n",
       " 'godot',\n",
       " 'terraform',\n",
       " 'QGIS',\n",
       " 'vscode',\n",
       " 'vscode',\n",
       " 'tgstation',\n",
       " 'Barotrauma',\n",
       " 'Kaiserreich-4']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names = list(df_all['repo_name'].unique())\n",
    "repo_names_clean = [repo_name.split('/')[-1] for repo_name in repo_names]\n",
    "repo_names_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test file\n",
      "start testing...\n",
      "test SDL\n",
      "(1, 1.0, 1.0)\n",
      "testing over\n",
      "augment SDL\n",
      "(1, 1.0, 1.0)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test dbeaver\n",
      "(415, 0.4674698795180723, 0.4674698795180723)\n",
      "testing over\n",
      "augment dbeaver\n",
      "(415, 0.653012048192771, 0.653012048192771)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test rstudio\n",
      "(79, 0.6075949367088608, 0.6075949367088608)\n",
      "testing over\n",
      "augment rstudio\n",
      "(79, 0.7215189873417721, 0.7215189873417721)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test symfony\n",
      "(148, 0.5, 0.5)\n",
      "testing over\n",
      "augment symfony\n",
      "(148, 0.9121621621621622, 0.9121621621621622)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test godot\n",
      "(633, 0.6540284360189573, 0.6540284360189573)\n",
      "testing over\n",
      "augment godot\n",
      "(633, 0.8688783570300158, 0.8688783570300158)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test terraform\n",
      "(164, 0.7073170731707317, 0.7073170731707317)\n",
      "testing over\n",
      "augment terraform\n",
      "(164, 0.7926829268292683, 0.7926829268292683)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test QGIS\n",
      "(311, 0.3311897106109325, 0.3311897106109325)\n",
      "testing over\n",
      "augment QGIS\n",
      "(311, 0.9614147909967846, 0.9614147909967846)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test vscode\n",
      "(1033, 0.6902226524685382, 0.6902226524685382)\n",
      "testing over\n",
      "augment vscode\n",
      "(1033, 0.9351403678606002, 0.9351403678606002)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test vscode\n",
      "(979, 0.676200204290092, 0.676200204290092)\n",
      "testing over\n",
      "augment vscode\n",
      "(979, 0.9560776302349336, 0.9560776302349336)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test tgstation\n",
      "(843, 0.5800711743772242, 0.5800711743772242)\n",
      "testing over\n",
      "augment tgstation\n",
      "(843, 0.9478054567022538, 0.9478054567022538)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test Barotrauma\n",
      "(378, 0.5502645502645502, 0.5502645502645502)\n",
      "testing over\n",
      "augment Barotrauma\n",
      "(378, 0.9365079365079365, 0.9365079365079365)\n",
      "Augment over\n",
      "Creating test file\n",
      "start testing...\n",
      "test Kaiserreich-4\n",
      "(947, 0.6430834213305174, 0.6430834213305174)\n",
      "testing over\n",
      "augment Kaiserreich-4\n",
      "(947, 0.9841605068637803, 0.9841605068637803)\n",
      "Augment over\n",
      "[\n",
      "    {\n",
      "        \"RESULTS FOR\": \"SDL\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 1.0,\n",
      "            \"Recall\": 1.0,\n",
      "            \"Precision\": 1.0\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 1.0,\n",
      "            \"Recall\": 1.0,\n",
      "            \"Precision\": 1.0\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"dbeaver\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.4674698795180723,\n",
      "            \"Recall\": 0.4674698795180723,\n",
      "            \"Precision\": 0.4674698795180723\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.653012048192771,\n",
      "            \"Recall\": 0.653012048192771,\n",
      "            \"Precision\": 0.653012048192771\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"rstudio\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.6075949367088608,\n",
      "            \"Recall\": 0.6075949367088608,\n",
      "            \"Precision\": 0.6075949367088608\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.7215189873417721,\n",
      "            \"Recall\": 0.7215189873417721,\n",
      "            \"Precision\": 0.7215189873417721\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"symfony\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.5,\n",
      "            \"Recall\": 0.5,\n",
      "            \"Precision\": 0.5\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.9121621621621622,\n",
      "            \"Recall\": 0.9121621621621622,\n",
      "            \"Precision\": 0.9121621621621622\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"godot\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.6540284360189573,\n",
      "            \"Recall\": 0.6540284360189573,\n",
      "            \"Precision\": 0.6540284360189573\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.8688783570300157,\n",
      "            \"Recall\": 0.8688783570300158,\n",
      "            \"Precision\": 0.8688783570300158\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"terraform\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.7073170731707317,\n",
      "            \"Recall\": 0.7073170731707317,\n",
      "            \"Precision\": 0.7073170731707317\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.7926829268292683,\n",
      "            \"Recall\": 0.7926829268292683,\n",
      "            \"Precision\": 0.7926829268292683\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"QGIS\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.3311897106109325,\n",
      "            \"Recall\": 0.3311897106109325,\n",
      "            \"Precision\": 0.3311897106109325\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.9614147909967846,\n",
      "            \"Recall\": 0.9614147909967846,\n",
      "            \"Precision\": 0.9614147909967846\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"vscode\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.6902226524685382,\n",
      "            \"Recall\": 0.6902226524685382,\n",
      "            \"Precision\": 0.6902226524685382\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.9351403678606002,\n",
      "            \"Recall\": 0.9351403678606002,\n",
      "            \"Precision\": 0.9351403678606002\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"vscode\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.676200204290092,\n",
      "            \"Recall\": 0.676200204290092,\n",
      "            \"Precision\": 0.676200204290092\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.9560776302349336,\n",
      "            \"Recall\": 0.9560776302349336,\n",
      "            \"Precision\": 0.9560776302349336\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"tgstation\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.5800711743772242,\n",
      "            \"Recall\": 0.5800711743772242,\n",
      "            \"Precision\": 0.5800711743772242\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.9478054567022538,\n",
      "            \"Recall\": 0.9478054567022538,\n",
      "            \"Precision\": 0.9478054567022538\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"Barotrauma\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.5502645502645502,\n",
      "            \"Recall\": 0.5502645502645502,\n",
      "            \"Precision\": 0.5502645502645502\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.9365079365079365,\n",
      "            \"Recall\": 0.9365079365079365,\n",
      "            \"Precision\": 0.9365079365079365\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"RESULTS FOR\": \"Kaiserreich-4\",\n",
      "        \"result_balanced\": {\n",
      "            \"F1\": 0.6430834213305174,\n",
      "            \"Recall\": 0.6430834213305174,\n",
      "            \"Precision\": 0.6430834213305174\n",
      "        },\n",
      "        \"result_augmented\": {\n",
      "            \"F1\": 0.9841605068637803,\n",
      "            \"Recall\": 0.9841605068637803,\n",
      "            \"Precision\": 0.9841605068637803\n",
      "        }\n",
      "    }\n",
      "]\n",
      "Writing output to file\n",
      "Deleting tmp files\n",
      "Exit.\n"
     ]
    }
   ],
   "source": [
    "path_test = r\"..\\temp\\temp_eval.txt\"\n",
    "path_train = r\"..\\temp\\temp_train.txt\"\n",
    "data_out_path = r\"..\\results\\repo_output_0.3large_train_0.5_repoTrain.json\"\n",
    "f_out = data_out_path\n",
    "output = []\n",
    "\n",
    "for i in range(len(repo_names)):\n",
    "    repo_name_clean= repo_names_clean[i]\n",
    "    repo_name = repo_names[i]\n",
    "\n",
    "    repo_df = df_all[df_all['repo_name']==repo_name]\n",
    "    # split dataset to train and dev samples\n",
    "    RANDOM_SEED = 12\n",
    "    x_train, x_test, y_train, y_test = train_test_split(repo_df['descriptions'], repo_df['labels'],\n",
    "                                                 test_size=0.5,\n",
    "                                                 random_state=RANDOM_SEED)\n",
    "    df_train_r = pd.concat([x_train, y_train], axis=1).reset_index(drop=True)\n",
    "    df_eval_r = pd.concat([x_test, y_test], axis=1).reset_index(drop=True)\n",
    "\n",
    "    df_train_r['data'] = df_train_r['labels'] + \" \" + df_train_r['descriptions']\n",
    "    df_train_r = df_train_r[['data']]\n",
    "\n",
    "    df_eval_r['data'] = df_eval_r['labels'] + \" \" + df_eval_r['descriptions']\n",
    "    df_eval_r = df_eval_r[['data']]\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Creating test file\")\n",
    "    df_eval_r.to_csv(path_test,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "    # now perform an eval with the eval dataset,\n",
    "    \n",
    "    # then combine the train repo with the overall training dataset \n",
    "    # now evaluate the performance of the larger trained dataset\n",
    "\n",
    "    print(\"start testing...\")\n",
    "    print(f\"test {repo_name_clean}\")\n",
    "    res = model.test(path_test)\n",
    "    print(res)\n",
    "    # get benchmarks\n",
    "    precision = res[1]\n",
    "    recall = res[2]\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    result_balanced = {\n",
    "        'F1': f1,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision\n",
    "    }\n",
    "\n",
    "    print(\"testing over\")\n",
    "    # print(json.dumps(result_balanced, indent=4))\n",
    "\n",
    "    df_train_repo_all = df_train.append(df_train_r)\n",
    "    df_train_repo_all.to_csv(path_train,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "    model_2 = fasttext.train_supervised(input=path_train, lr=1.0, epoch=25, wordNgrams=2)\n",
    "    res = model_2.test(path_test)\n",
    "    print(f\"augment {repo_name_clean}\")\n",
    "    print(res)\n",
    "\n",
    "    precision = res[1]\n",
    "    recall = res[2]\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    result_augmented = {\n",
    "        'F1': f1,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision\n",
    "    }\n",
    "    print(\"Augment over\")\n",
    "    # print(json.dumps(result_augmented, indent=4))\n",
    "\n",
    "    output_temp = {\n",
    "        'RESULTS FOR': repo_name_clean,\n",
    "        'result_balanced': result_balanced,\n",
    "        'result_augmented': result_augmented\n",
    "    }\n",
    "\n",
    "    output.append(output_temp)\n",
    "\n",
    "dump = json.dumps(output, indent=4)\n",
    "print(dump)\n",
    "# write to output\n",
    "print(\"Writing output to file\")\n",
    "# f_out = data_out_path + f\"\\REPO_output.txt\"\n",
    "o = open(f_out, 'w', encoding=\"UTF-8\")\n",
    "o.write(dump)\n",
    "o.close()\n",
    "# except:\n",
    "# print(\"An Error occurred\")\n",
    "# # in any case delete existing temporary files\n",
    "# finally:\n",
    "print(\"Deleting tmp files\")\n",
    "if os.path.exists(path_train):\n",
    "    os.remove(path_train)\n",
    "if os.path.exists(path_test):\n",
    "    os.remove(path_test)\n",
    "print(\"Exit.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ef95568004652f776bd8622263a31e0f4453e284693cb553c5f4e384f04eb19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
