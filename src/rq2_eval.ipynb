{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext_comparison_function import eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import neattext.functions as nfx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>repo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"script path builtin variable (a la `__file__`...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"give lobby creator extra powers hey</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>dmtmm congratulations! guys great works past h...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"router - avoid regex matching possible given ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__enhancement</td>\n",
       "      <td>\"improve command history currently</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 labels                                       descriptions  \\\n",
       "0  __label__enhancement  \"script path builtin variable (a la `__file__`...   \n",
       "1  __label__enhancement               \"give lobby creator extra powers hey   \n",
       "2  __label__enhancement  dmtmm congratulations! guys great works past h...   \n",
       "3  __label__enhancement  \"router - avoid regex matching possible given ...   \n",
       "4  __label__enhancement                 \"improve command history currently   \n",
       "\n",
       "  repo_name  \n",
       "0     other  \n",
       "1     other  \n",
       "2     other  \n",
       "3     other  \n",
       "4     other  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# custom data set\n",
    "data_in_path = r\"..\\dataset\\CLEAN_balanced_data.csv\"\n",
    "data_out_path = r\"..\\results\\output.txt\"\n",
    "df = pd.read_csv(data_in_path)\n",
    "df = df.dropna()\n",
    "# df['data'] = \"__label__\" + df['labels'] + \" \" + df['descriptions']\n",
    "# df['data'] = df['labels'] + \" \" + df['descriptions']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29625, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"..\\dataset\\ft_bal.txt\"\n",
    "# df['data'] = \"__label__\" + df['labels'] + \" \" + df['descriptions']\n",
    "df['data'] = df['labels'] + \" \" + df['descriptions']\n",
    "df_file = df[['data']]\n",
    "df_file.to_csv(data_path,index=False,header=False,sep=\"\\t\",encoding='utf-8-sig')\n",
    "df_file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dataset to array\n",
      "New tenfold iteration: 1 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 1,\n",
      "    \"F1\": 0.6282642089093702,\n",
      "    \"Recall\": 0.6282642089093702,\n",
      "    \"Precision\": 0.6282642089093702\n",
      "}\n",
      "New tenfold iteration: 2 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 2,\n",
      "    \"F1\": 0.6763803680981595,\n",
      "    \"Recall\": 0.6763803680981595,\n",
      "    \"Precision\": 0.6763803680981595\n",
      "}\n",
      "New tenfold iteration: 3 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 3,\n",
      "    \"F1\": 0.6437308868501529,\n",
      "    \"Recall\": 0.6437308868501529,\n",
      "    \"Precision\": 0.6437308868501529\n",
      "}\n",
      "New tenfold iteration: 4 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 4,\n",
      "    \"F1\": 0.6724409448818898,\n",
      "    \"Recall\": 0.6724409448818898,\n",
      "    \"Precision\": 0.6724409448818898\n",
      "}\n",
      "New tenfold iteration: 5 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 5,\n",
      "    \"F1\": 0.6416938110749185,\n",
      "    \"Recall\": 0.6416938110749185,\n",
      "    \"Precision\": 0.6416938110749185\n",
      "}\n",
      "New tenfold iteration: 6 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 6,\n",
      "    \"F1\": 0.6224961479198767,\n",
      "    \"Recall\": 0.6224961479198767,\n",
      "    \"Precision\": 0.6224961479198767\n",
      "}\n",
      "New tenfold iteration: 7 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 7,\n",
      "    \"F1\": 0.6563944530046225,\n",
      "    \"Recall\": 0.6563944530046225,\n",
      "    \"Precision\": 0.6563944530046225\n",
      "}\n",
      "New tenfold iteration: 8 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 8,\n",
      "    \"F1\": 0.6151515151515151,\n",
      "    \"Recall\": 0.6151515151515151,\n",
      "    \"Precision\": 0.6151515151515151\n",
      "}\n",
      "New tenfold iteration: 9 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 9,\n",
      "    \"F1\": 0.664,\n",
      "    \"Recall\": 0.664,\n",
      "    \"Precision\": 0.664\n",
      "}\n",
      "New tenfold iteration: 10 -----------------------------------------\n",
      "Creating train file\n",
      "Creating test file\n",
      "start training...\n",
      "start testing...\n",
      "Fold over, here are results: \n",
      "{\n",
      "    \"10-Fold iteration:\": 10,\n",
      "    \"F1\": 0.6758957654723127,\n",
      "    \"Recall\": 0.6758957654723127,\n",
      "    \"Precision\": 0.6758957654723127\n",
      "}\n",
      "Done with 10 fold validation\n",
      "{\n",
      "    \"Results\": {\n",
      "        \"F1\": 0.6496448101362818,\n",
      "        \"Recall\": 0.6496448101362818,\n",
      "        \"Precision\": 0.6496448101362818\n",
      "    },\n",
      "    \"Details\": [\n",
      "        {\n",
      "            \"10-Fold iteration:\": 1,\n",
      "            \"F1\": 0.6282642089093702,\n",
      "            \"Recall\": 0.6282642089093702,\n",
      "            \"Precision\": 0.6282642089093702\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 2,\n",
      "            \"F1\": 0.6763803680981595,\n",
      "            \"Recall\": 0.6763803680981595,\n",
      "            \"Precision\": 0.6763803680981595\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 3,\n",
      "            \"F1\": 0.6437308868501529,\n",
      "            \"Recall\": 0.6437308868501529,\n",
      "            \"Precision\": 0.6437308868501529\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 4,\n",
      "            \"F1\": 0.6724409448818898,\n",
      "            \"Recall\": 0.6724409448818898,\n",
      "            \"Precision\": 0.6724409448818898\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 5,\n",
      "            \"F1\": 0.6416938110749185,\n",
      "            \"Recall\": 0.6416938110749185,\n",
      "            \"Precision\": 0.6416938110749185\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 6,\n",
      "            \"F1\": 0.6224961479198767,\n",
      "            \"Recall\": 0.6224961479198767,\n",
      "            \"Precision\": 0.6224961479198767\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 7,\n",
      "            \"F1\": 0.6563944530046225,\n",
      "            \"Recall\": 0.6563944530046225,\n",
      "            \"Precision\": 0.6563944530046225\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 8,\n",
      "            \"F1\": 0.6151515151515151,\n",
      "            \"Recall\": 0.6151515151515151,\n",
      "            \"Precision\": 0.6151515151515151\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 9,\n",
      "            \"F1\": 0.664,\n",
      "            \"Recall\": 0.664,\n",
      "            \"Precision\": 0.664\n",
      "        },\n",
      "        {\n",
      "            \"10-Fold iteration:\": 10,\n",
      "            \"F1\": 0.6758957654723127,\n",
      "            \"Recall\": 0.6758957654723127,\n",
      "            \"Precision\": 0.6758957654723127\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Writing output to file\n",
      "Deleting tmp files\n",
      "Exit.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# path_train = os.path.dirname(__file__) + './tmp/tmp_train.txt'\n",
    "# path_test = os.path.dirname(__file__) + './tmp/tmp_test.txt'\n",
    "\n",
    "path_test = r\"..\\temp\\temp_eval.txt\"\n",
    "path_train = r\"..\\temp\\temp_train.txt\"\n",
    "data_out_path = r\"..\\results\\output_ft_regular.txt\"\n",
    "data_set = data_path\n",
    "f_out = data_out_path\n",
    "# try:\n",
    "print(\"Converting dataset to array\")\n",
    "# f = open(data_set, 'r+', encoding=\"UTF-8\")\n",
    "\n",
    "data = array(df_file['data'])\n",
    "# f.close()\n",
    "\n",
    "# array for details\n",
    "fold_outputs = []\n",
    "\n",
    "# 10 fold loop\n",
    "kfold = KFold(10, shuffle=True, random_state=1)\n",
    "fold = 1\n",
    "for train, test in kfold.split(data):\n",
    "    print(\"New tenfold iteration:\", str(fold), \"-----------------------------------------\")\n",
    "    print(\"Creating train file\")\n",
    "    tmp_train = data[train]\n",
    "    pd.DataFrame(tmp_train).to_csv(path_train,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "    print(\"Creating test file\")\n",
    "    tmp_test = data[test]\n",
    "    pd.DataFrame(tmp_test).to_csv(path_test,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"start training...\")\n",
    "    # use this model if you want to enable auto-tuning. Sadly we did not get it to work during our project\n",
    "    # model = fasttext.train_supervised(input=path_train, autotuneValidationFile=path_test, autotuneDuration=600)\n",
    "    # model = fasttext.train_supervised(input=path_train)  # normal fasttext classification without autotuning\n",
    "    model = fasttext.train_supervised(input=path_train, lr=1.0, epoch=25, wordNgrams=2)\n",
    "    print(\"start testing...\")\n",
    "    res = model.test(path_test)\n",
    "    # get benchmarks\n",
    "    precision = res[1]\n",
    "    recall = res[2]\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    result = {\n",
    "        '10-Fold iteration:': fold,\n",
    "        'F1': f1,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision\n",
    "    }\n",
    "    # log\n",
    "    print(\"Fold over, here are results: \")\n",
    "    print(json.dumps(result, indent=4))\n",
    "    fold_outputs.append(result)\n",
    "    fold += 1\n",
    "print(\"Done with 10 fold validation\")\n",
    "# calculate over-all results\n",
    "mean_recall = 0\n",
    "mean_precision = 0\n",
    "mean_f1 = 0\n",
    "for f in fold_outputs:\n",
    "    mean_f1 += (f['F1'] / 10)\n",
    "    mean_recall += (f['Recall'] / 10)\n",
    "    mean_precision += (f['Precision'] / 10)\n",
    "    # compile results as json\n",
    "output = {\n",
    "    'Results': {\n",
    "        'F1': mean_f1,\n",
    "        'Recall': mean_recall,\n",
    "        'Precision': mean_precision\n",
    "    },\n",
    "    'Details': fold_outputs\n",
    "}\n",
    "dump = json.dumps(output, indent=4)\n",
    "print(dump)\n",
    "# write to output\n",
    "print(\"Writing output to file\")\n",
    "o = open(f_out, 'w', encoding=\"UTF-8\")\n",
    "o.write(dump)\n",
    "o.close()\n",
    "# except:\n",
    "# print(\"An Error occurred\")\n",
    "# # in any case delete existing temporary files\n",
    "# finally:\n",
    "print(\"Deleting tmp files\")\n",
    "if os.path.exists(path_train):\n",
    "    os.remove(path_train)\n",
    "if os.path.exists(path_test):\n",
    "    os.remove(path_test)\n",
    "print(\"Exit.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan / work steps\n",
    "need to split the repo level data into test/train datasets\n",
    "\n",
    "need to train a model with a simple test/ train split from the balanced data\n",
    "then use that model to predict on each of the repo datasets\n",
    "\n",
    "then split each repo dataset into test train\n",
    "\n",
    "include the repo data inside the training data\n",
    "then repredict with it\n",
    "see if it improves it at all. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to organize the data into separate groups for each of the different repo\n",
    "then run the eval function over each of them. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating creating model and using it to predict repo issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# custom data set\n",
    "data_in_path = r\"..\\dataset\\CLEAN_balanced_data.csv\"\n",
    "data_out_path = r\"..\\results\\output.txt\"\n",
    "data_df = pd.read_csv(data_in_path)\n",
    "data_df = data_df.dropna()\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to train and dev samples\n",
    "RANDOM_SEED = 12\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_df['descriptions'], data_df['labels'],\n",
    "                                                 test_size=0.3,\n",
    "                                                 random_state=RANDOM_SEED)\n",
    "df_train = pd.concat([x_train, y_train], axis=1).reset_index(drop=True)\n",
    "df_eval = pd.concat([x_test, y_test], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['data'] = df_train['labels'] + \" \" + df_train['descriptions']\n",
    "df_train = df_train[['data']]\n",
    "\n",
    "df_train['data'] = df_train['labels'] + \" \" + df_train['descriptions']\n",
    "df_train = df_train[['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train file\")\n",
    "pd.DataFrame(tmp_train).to_csv(path_train,index=False,header=False,encoding='utf-8-sig')\n",
    "\n",
    "print(\"Creating test file\")\n",
    "pd.DataFrame(tmp_test).to_csv(path_test,index=False,header=False,encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ef95568004652f776bd8622263a31e0f4453e284693cb553c5f4e384f04eb19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
